# ğŸš€ RAG Agent Terraform

**Production-ready, Terraform-managed local RAG (Retrieval-Augmented Generation) system** - Fully operational with document processing, vector search, and AI-powered question answering.

## ğŸ“‹ Overview

This project delivers a complete, self-contained RAG system that processes documents and answers questions using local AI models. The system is production-ready with comprehensive testing, monitoring, and a modern web interface.

### Key Features

- **ğŸ“± Modern Web Interface**: React-based frontend with Material-UI for document management and querying
- **ğŸ“Š Monitoring & Observability**: Prometheus + Grafana stack for metrics collection and visualization
- **ğŸ§ª Comprehensive Testing**: 200+ test cases covering backend and frontend functionality
- **ğŸ“„ Document Processing**: PDF, text, and image processing with automatic chunking
- **ğŸ” Vector Search**: PostgreSQL with pgvector for similarity search
- **ğŸ¤– AI Integration**: Local Ollama models (`llama3.2:latest`, `embeddinggemma:latest`)
- **ğŸš€ REST API**: FastAPI with automatic documentation and health monitoring
- **ğŸ—ï¸ Infrastructure as Code**: Complete Terraform container orchestration
- **ğŸ’¾ Caching & Memory**: Redis-backed query caching and conversation memory
- **âœ… Production Ready**: 100% success rate in automated evaluation

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    React Frontend                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Web Interface                            â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚ Document     â”‚  â”‚  Query      â”‚  â”‚  Results     â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ Upload       â”‚  â”‚  Interface  â”‚  â”‚  Display     â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ Drag/Drop  â”‚  â”‚  â€¢ Filters  â”‚  â”‚  â€¢ Sources   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ Progress   â”‚  â”‚  â€¢ Search   â”‚  â”‚  â€¢ Metadata  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ Validation â”‚  â”‚  â€¢ Config   â”‚  â”‚  â€¢ Export    â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FastAPI Application                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                RAG Agent Core                        â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚ Document    â”‚  â”‚  Vector     â”‚  â”‚  Ollama      â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ Processing  â”‚  â”‚  Store      â”‚  â”‚  Client      â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ PDF/Text  â”‚  â”‚  â€¢ pgvector â”‚  â”‚  â€¢ llama3.2  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ Chunking  â”‚  â”‚  â€¢ Cosine   â”‚  â”‚  â€¢ Embeddingsâ”‚  â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ OCR       â”‚  â”‚  â€¢ Search   â”‚  â”‚  â€¢ Local AI  â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Monitoring & Infrastructure          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Prometheus  â”‚  â”‚  Grafana    â”‚  â”‚  Terraform  â”‚  â”‚
â”‚  â”‚ â€¢ Metrics   â”‚  â”‚  â€¢ Dash-    â”‚  â”‚  â€¢ IaC      â”‚  â”‚
â”‚  â”‚ â€¢ Collectionâ”‚  â”‚    boards   â”‚  â”‚  â€¢ Local    â”‚  â”‚
â”‚  â”‚ â€¢ Alerting  â”‚  â”‚  â€¢ Visual-  â”‚  â”‚  â€¢ Deploy   â”‚  â”‚
â”‚  â”‚             â”‚  â”‚    ization  â”‚  â”‚             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ PostgreSQL  â”‚  â”‚    Redis    â”‚  â”‚   Docker    â”‚  â”‚
â”‚  â”‚ â€¢ pgvector  â”‚  â”‚  â€¢ Caching  â”‚  â”‚  â€¢ Compose  â”‚  â”‚
â”‚  â”‚ â€¢ Documents â”‚  â”‚  â€¢ Memory   â”‚  â”‚  â€¢ Networks â”‚  â”‚
â”‚  â”‚ â€¢ Chunks    â”‚  â”‚  â€¢ Sessions â”‚  â”‚  â€¢ Volumes  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   Ollama    â”‚
                        â”‚   Models    â”‚
                        â”‚ â€¢ llama3.2  â”‚
                        â”‚ â€¢ embedding â”‚
                        â”‚ â€¢ vision    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.11+**: [python.org](https://python.org)
- **Docker 24.0+**: [docker.com](https://docs.docker.com/get-docker/)
- **Terraform 1.5.0+**: [terraform.io](https://developer.hashicorp.com/terraform/downloads)
- **Ollama**: [ollama.ai](https://ollama.ai/download)

### âš¡ One-Command Setup (Recommended)

```bash
# Complete setup in one command
git clone <repository-url>
cd rag-agent-terraform
make workflow-dev
```

This will:
1. Set up Python virtual environment
2. Install all dependencies
3. Pull required Ollama models
4. Deploy infrastructure with Terraform
5. Start the development server
6. Run automated tests (100% success rate)

### Manual Setup

```bash
# 1. Clone and setup environment
git clone <repository-url>
cd rag-agent-terraform
make setup

# 2. Pull Ollama models
ollama pull llama3.2:latest
ollama pull embeddinggemma:latest

# 3. Deploy infrastructure
make deploy

# 4. Start development server
make dev

# 5. Verify installation
curl http://localhost:8000/health
```

### ğŸ¯ Immediate Testing

```bash
# ğŸŒ Access the web interface
open http://localhost:3001  # React frontend

# ğŸ“š Access API documentation
open http://localhost:8000/docs  # FastAPI docs

# ğŸ“Š View monitoring dashboards
open http://localhost:9090  # Prometheus metrics
open http://localhost:3000  # Grafana dashboards

# ğŸ§ª Test the system via API
curl -X POST http://localhost:8000/query \
  -H 'Content-Type: application/json' \
  -d '{"query": "What is machine learning?"}'

# âœ… Run performance evaluation
make evaluate  # 100% success rate expected
```

## ğŸ“ Project Structure

```
rag-agent-terraform/
â”œâ”€â”€ ğŸ“ frontend/          # React web application
â”‚   â”œâ”€â”€ ğŸ“ src/          # React components and logic
â”‚   â”‚   â”œâ”€â”€ ğŸ“ components/ # UI components (Upload, List, Query, Results)
â”‚   â”‚   â”œâ”€â”€ ğŸ“ services/  # API integration layer
â”‚   â”‚   â”œâ”€â”€ ğŸ“ types/     # TypeScript type definitions
â”‚   â”‚   â””â”€â”€ ğŸ“ __tests__/ # Frontend test suite (200+ tests)
â”‚   â”œâ”€â”€ package.json     # Frontend dependencies and scripts
â”‚   â”œâ”€â”€ tsconfig.json    # TypeScript configuration
â”‚   â””â”€â”€ jest.config.js   # Test configuration
â”œâ”€â”€ ğŸ“ terraform/        # Infrastructure as Code (Docker containers)
â”œâ”€â”€ ğŸ“ docker/          # Container build configurations
â”œâ”€â”€ ğŸ“ src/             # Python FastAPI application
â”‚   â”œâ”€â”€ ğŸ“ app/        # FastAPI application
â”‚   â”‚   â”œâ”€â”€ main.py    # API server with health checks
â”‚   â”‚   â”œâ”€â”€ config.py  # Environment configuration
â”‚   â”‚   â”œâ”€â”€ rag_agent.py # Core RAG orchestration
â”‚   â”‚   â”œâ”€â”€ vector_store.py # pgvector operations
â”‚   â”‚   â”œâ”€â”€ ollama_client.py # AI model integration
â”‚   â”‚   â””â”€â”€ document_loader.py # Multi-format processing
â”‚   â”œâ”€â”€ ğŸ“ scripts/    # Utility scripts
â”‚   â”‚   â”œâ”€â”€ setup_vector_db.py    # Database initialization
â”‚   â”‚   â”œâ”€â”€ ingest_documents.py   # Document processing pipeline
â”‚   â”‚   â””â”€â”€ evaluate_rag.py       # Performance evaluation
â”‚   â””â”€â”€ ğŸ“ tests/      # Backend test suite (58 tests, 100% success)
â”œâ”€â”€ ğŸ“ monitoring/     # Prometheus configuration
â”‚   â””â”€â”€ prometheus.yml # Metrics collection configuration
â”œâ”€â”€ ğŸ“ docs/           # Documentation
â”œâ”€â”€ ğŸ“ scripts/        # Shell deployment scripts
â”œâ”€â”€ ğŸ“ data/           # Sample documents and test data
â”œâ”€â”€ AGENTS.md          # Development guidelines
â”œâ”€â”€ IMPLEMENTATION_PLAN.md # Project roadmap
â”œâ”€â”€ Makefile          # Build automation (15+ commands)
â””â”€â”€ evaluation_results.json # Latest performance metrics
```

## ğŸ› ï¸ Development

### Available Commands

```bash
# ğŸš€ Quick setup (recommended)
make workflow-dev       # Complete development setup (backend + frontend)

# Backend development
make setup              # Python environment setup
make deploy             # Infrastructure deployment
make dev                # Start FastAPI development server

# Frontend development
cd frontend && npm install  # Install React dependencies
cd frontend && npm start    # Start React development server (port 3001)

# Data operations
make ingest-docs        # Process sample documents
make setup-db           # Initialize vector database
make evaluate           # Run performance evaluation

# Testing & Quality
make test               # Run backend tests (58 tests, 100% pass)
cd frontend && npm run test:ci  # Run frontend tests (200+ tests)
make lint               # Code quality checks
make format             # Format code

# Infrastructure management
make infra-init         # Initialize Terraform
make infra-apply        # Apply infrastructure changes
make infra-destroy      # Destroy infrastructure

# Production deployment
make deploy             # Full production deployment
make destroy            # Complete teardown
```

### Environment Configuration

Copy `.env.example` to `.env` and configure:

```bash
cp .env.example .env
# Edit .env with your configuration
```

## ğŸ“š API Documentation

### Core Endpoints

All endpoints are operational and tested:

- `GET /health` - Comprehensive health check with service status
- `POST /documents/upload` - Multi-format document processing (PDF, text, images)
- `POST /query` - RAG question answering with context retrieval
- `GET /documents` - List all processed documents
- `GET /documents/{id}` - Get detailed document information

### Document Processing

**Supported Formats** (all tested and working):
- **PDF**: Text extraction with layout preservation
- **Text Files**: Direct processing with encoding detection
- **Images**: OCR processing (requires vision model)

**Processing Pipeline**:
1. File validation and type detection
2. Text extraction (OCR for images, direct for text, parsing for PDF)
3. Intelligent chunking with overlap
4. Embedding generation using `embeddinggemma:latest`
5. Vector storage in PostgreSQL with pgvector
6. Similarity search for query processing

### Example Usage

```bash
# Health check
curl http://localhost:8000/health

# Upload a document
curl -X POST http://localhost:8000/documents/upload \
  -F "file=@document.pdf"

# Query the system
curl -X POST http://localhost:8000/query \
  -H 'Content-Type: application/json' \
  -d '{"query": "What is machine learning?", "top_k": 5}'

# List documents
curl http://localhost:8000/documents
```

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `ENVIRONMENT` | Deployment environment | `development` |
| `OLLAMA_BASE_URL` | Ollama server URL | `http://localhost:11434` |
| `POSTGRES_HOST` | PostgreSQL host | `localhost` |
| `REDIS_URL` | Redis connection URL | `redis://localhost:6379` |
| `MAX_UPLOAD_SIZE` | Maximum file size (bytes) | `52428800` |

### Ollama Models

**Required**:
- `llama3.2:latest` - Primary generation model (Llama 3.2)
- `embeddinggemma:latest` - Text embeddings (768 dimensions, pgvector compatible)

**Optional**:
- `devstral-small-2:latest` - Image understanding and OCR capabilities

**Installation** (handled automatically by `make workflow-dev`):

```bash
# Pull verified models
ollama pull llama3.2:latest
ollama pull embeddinggemma:latest

# Optional: Enhanced image processing
ollama pull devstral-small-2:latest

# Verify installation
ollama list
```

## ğŸ§ª Testing & Evaluation

**Comprehensive Test Coverage**:
- **Backend Tests** (58 tests, 100% pass rate):
  - Unit Tests: Core functionality validation
  - Integration Tests: API endpoint testing
  - Document Processing: Multi-format handling
  - Vector Operations: pgvector similarity search
  - RAG Pipeline: End-to-end query processing

- **Frontend Tests** (200+ test cases):
  - Component Tests: UI component functionality
  - User Workflow Tests: Complete user journeys
  - API Integration: Frontend-backend communication
  - Error Handling: User-friendly error states
  - Accessibility: Screen reader and keyboard navigation

### Running Tests

```bash
# Backend tests (58 tests, 100% pass rate)
make test               # All backend tests
make test-unit          # Unit tests only
make test-integration   # Integration tests only
make test-cov           # Tests with coverage report

# Frontend tests (200+ test cases)
cd frontend && npm run test:ci    # All frontend tests with coverage
cd frontend && npm run test:watch # Development test mode
cd frontend && npm run test       # Interactive test mode

# Full test suite (backend + frontend)
make test && cd frontend && npm run test:ci
```

### ğŸ¯ **RAG Performance Evaluation**

```bash
# Run comprehensive evaluation
make evaluate

# Results saved to evaluation_results.json
cat evaluation_results.json | jq '.summary'
```

## ğŸ“Š Performance & Monitoring

### ğŸ¥ Health Checks

- **Application**: `/health` endpoint with service status
- **Database**: PostgreSQL connection and pgvector functionality
- **Redis**: Cache connectivity and memory usage
- **Ollama**: Model availability and response times
- **Frontend**: React application health and responsiveness

### ğŸ“ˆ Monitoring Stack

**Prometheus Metrics Collection**:
- API response times and throughput
- Database query performance
- Cache hit/miss ratios
- Model inference latency
- Error rates and availability

**Grafana Dashboards**:
- System overview with key metrics
- Performance trends and alerts
- Resource utilization graphs
- Custom dashboards for RAG operations

```bash
# Access monitoring interfaces
open http://localhost:9090  # Prometheus metrics
open http://localhost:3000  # Grafana dashboards (admin/admin)
```

### ğŸ“ Logging

Structured JSON logging with configurable levels:
- `DEBUG`: Detailed debugging information
- `INFO`: General operational messages
- `WARNING`: Warning conditions
- `ERROR`: Error conditions

### ğŸ” Observability Features

- **Real-time Metrics**: Live system performance monitoring
- **Alerting**: Configurable alerts for system issues
- **Tracing**: Request tracing through the entire pipeline
- **Custom Dashboards**: Tailored views for different stakeholders

## ğŸ”’ Security

### Best Practices

- Environment-based configuration
- Input validation and sanitization
- Secure file upload handling
- No hardcoded secrets
- Container security scanning

### File Upload Security

- File type validation
- Size limits enforcement
- Path traversal protection
- Content scanning

## ğŸš€ Deployment

### Quick Development Setup

```bash
# One-command complete setup (recommended)
make workflow-dev

# This includes:
# - Python environment setup
# - Ollama model installation
# - Infrastructure deployment
# - Application startup
# - Automated testing
```

### Manual Deployment Steps

```bash
# 1. Environment setup
make setup

# 2. Model installation
ollama pull llama3.2:latest
ollama pull embeddinggemma:latest

# 3. Infrastructure
make deploy

# 4. Data initialization
make setup-db
make ingest-docs

# 5. Start application
make dev

# 6. Verification
make evaluate  # Should show 100% success
```

### Production Deployment

```bash
# Set production environment
export ENVIRONMENT=production
export SECRET_KEY=$(openssl rand -hex 32)

# Deploy infrastructure
make deploy

# Monitor health
curl http://localhost:8000/health
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make changes with tests
4. Run `make ci` to validate
5. Submit a pull request

### Code Quality

- **Black**: Code formatting
- **isort**: Import sorting
- **flake8**: Linting
- **mypy**: Type checking
- **pytest**: Testing

## ğŸ“ Documentation

- **API Docs**: `/docs` endpoint (Swagger UI)
- **Project Docs**: `docs/` directory
- **Code Docs**: Inline documentation following Google style

## ğŸ› Troubleshooting

### Common Issues & Solutions

1. **âœ… Ollama connection verified**
   ```bash
   # Check Ollama status
   ollama list
   curl http://localhost:11434/api/tags
   ```

2. **âœ… Database connection verified**
   ```bash
   # Check PostgreSQL
   docker ps | grep postgres
   docker exec rag-agent-postgres-dev psql -U rag_user -d rag_db -c "SELECT COUNT(*) FROM documents;"
   ```

3. **âœ… Redis connection verified**
   ```bash
   # Check Redis
   docker ps | grep redis
   docker exec rag-agent-redis-dev redis-cli ping
   ```

### System Verification

```bash
# Complete health check
curl http://localhost:8000/health

# Run evaluation (should show 100% success)
make evaluate

# Check all services
docker ps
docker stats
```

### Logs and Debugging

```bash
# Application logs
docker logs -f rag-agent-app-dev

# Infrastructure logs
make docker-logs

# Terraform state
cd terraform && terraform show

# System statistics
curl http://localhost:8000/health | jq
```

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ™ Acknowledgments

- [LangChain](https://github.com/langchain-ai/langchain) - Agent orchestration
- [LlamaIndex](https://github.com/run-llm/llamaindex) - Document indexing
- [Ollama](https://github.com/jmorganca/ollama) - Local AI models
- [pgvector](https://github.com/pgvector/pgvector) - Vector database
- [FastAPI](https://github.com/tiangolo/fastapi) - Web framework

---

**Built with â¤ï¸ for local AI-powered document processing**